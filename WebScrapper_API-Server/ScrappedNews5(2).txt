Done with Query Page:1, PageSize:5

Article Data
['article', 'news']
['Technology']
BBC
https://www.bbc.com/news/articles/cdd4vn6p601o
None
2024-10-18T11:20:32.770Z
Instagram defends new teen safety features after criticism
Instagram has defended new features aimed at protecting teens from sextortion attempts on the platform, following criticism they do not go far enough.Parent company Meta said on Thursday its new tools - which include preventing screenshots or screen-recordings of disappearing images and videos - were part of "ongoing efforts" to stop criminals tricking teens into sending intimate images to scammers.The NSPCC said the moves were a "step in the right direction".But Arturo Béjar, former Meta employee turned whistleblower, told BBC News there were easier ways Instagram could protect young people from unwanted contact.
"The most impactful thing they could do is make it easy for a teen to flag when they think the account asking to follow them is pretending to be a teen," Mr Béjar said."The way the product is designed, by the time they need to report for sextortion the damage is already done."Meta said its tools, developed using user feedback, give teens clear and straightforward ways to report inappropriate behaviour or harassment. It said it also offers dedicated mechanisms for flagging unwanted nude images and prioritises such reports, adding it is inaccurate to suggest people cannot report accounts pretending to be teens as it has options to report fraud or scams.Richard Collard, the NSPCC's associate head of child safety online policy, said: "Questions remain as to why Meta are not rolling out similar protections on all their products, including on WhatsApp where grooming and sextortion also take place at scale".The UK's communications watchdog Ofcom warned that social media companies will face fines if they fail to keep children safe.
Sextortion, which sees scammers trick people into sending sexually explicit material before blackmailing them, has become a dominant form of intimate image abuse.Law enforcement agencies around the world have reported a rise in the number of sextortion scams taking place across social media platforms, with these often targeting teenage boys.The UK's Internet Watch Foundation said in March that 91% of sextortion reports it received in 2023 related to boys.The shame, stress and isolation felt by victims of sextortion crimes, who are harassed and told their images will be shared publicly if they do not pay blackmailers, has led some to take their own lives.Parents of teenagers who have died after being targeted have called on social media firms to do more to stop it.Ros Dowey, the mother of 16-year-old Murray Dowey, who died by suicide in 2023 after being targeted by a sextortion gang on Instagram, previously told the BBC that Meta was not doing "nearly enough to safeguard and protect our children when they use their platforms".
Meta said its new safety features and campaign are designed to build on tools already available to teens and parents on the platform.Antigone Davis, Meta’s head of global safety, said a new Instagram campaign aims to give children and parents information about how to spot sextortion attempts in case perpetrators evade its tools for detecting them."We have put in built-in protections so that parents do not have to do a thing to try and protect their teens," she told BBC News."That said, this is the kind of adversarial crime where whatever protections we put in place, these extortion scammers are going to try and get around them."It will hide people's follower and following lists from potential sextortion accounts, and let teens know if they are speaking to someone who seems to be in a different country.Sextortion expert Paul Raffile told the BBC in May that sextorters try to find teen accounts in following and follower lists after searching for high schools and youth sports teams on platforms.Instagram will also prevent screenshots of images and videos sent in private messages with its "view once" or "allow replay" mechanisms - which can be selected by users when sending an image or video to others.Users will not be able to open these forms of media at all on Instagram web. But Mr Béjar said it could give people "a false sense of security" as attackers could photograph an image on a screen using a separate device.According to Meta, the feature goes beyond protections offered by other social media platforms that tell users when their images or videos have been screenshotted, but do not prevent it.Mr Béjar - who has called on the platform to create a button that lets teens straightforwardly report inappropriate behaviour or contact - also said nude images sent to younger teens should be blocked, not just blurred. He added that younger users should have clearer, stronger warnings about sending such images than those currently offered.Meta says its nudity protections were designed in liaison with child protection experts to educate people about the risks of seeing and sharing such images in a way that does not shame or scare teens by disrupting conversations.The company is currently moving under-18s into Teen Account experiences on Instagram with stricter settings turned on by default – with parental supervision required for younger teens to turn them off.But some parents and experts have said safety controls for teen accounts shift the responsibility of spotting and reporting potential threats onto them.Dame Melanie Dawes, the chief executive of the regulator Ofcom, told the BBC said it was the responsibility of the firms - not parents or children - to make sure people were safe online ahead of the implementation of the Online Safety Act next year.

Article Data
['article', 'news']
['Technology']
BBC
https://www.bbc.com/news/articles/c20pvkg35xyo
None
2024-10-18T10:08:10.231Z
Alleged Bitcoin hacker searched 'signs the FBI is after you'
A man arrested in connection with a hack of the US markets regulator's X account searched "how can I know for sure if I am being investigated by the FBI," according to court documents.Eric Council Jr, 25, of Athens, Georgia, is also alleged to have searched for "signs that you are under investigation by law enforcement... even if you have not been contacted by them".He is accused of being part of a group which hacked the Securities and Exchange Commission (SEC) social media in January to make a fake post about Bitcoin, causing the cryptocurrency to surge in value.The regulator previously admitted a key security step to access its X account had been removed. 
The post sent by hackers on the SEC's X account made the false claim the regulator had allowed Bitcoin to be part of mainstream investment funds.This caused the price of the cryptocurrency to rise by about $1,000 (£770), according to the US Department of Justice, before falling by $2,000 when it was found to be untrue.Despite the confusion caused by the hack, the SEC later approved Bitcoin to be a part of mainstream investment, through what are known as spot Bitcoin exchange-traded funds.According to court documents, Eric Council Jr went under the aliases Ronin, Easymunny, and AGiantSchnauzer online, and searched "SECGOV hack" and "Telegram sim swap".He is also alleged to have searched "federal identity theft statute" and "how long does it take to delete Telegram account".Telegram is a messaging app with more than 950 million monthly active users.
The SEC has confirmed its account was compromised by a Sim swap attack.This is when someone fraudulently gets a mobile phone carrier to apply an existing telephone number to a new Sim card.In this case, the alleged perpetrator is accused of creating a fake ID with the details of an SEC employee which were passed on to him by co-conspirators.He is then alleged to have used these details to get the employee's mobile number transferred to a new Sim.Co-conspirators are alleged to have used access codes sent to the phone to login to the SEC's X account.This was made easier due to a lack of adequate protection on the account.SEC staff had asked X in July 2023 to suspend multi-factor authentication (MFA), a security measure used to help verify the person logging in.It subsequently re-enabled MFA after the hack.Eric Council Jr is charged with one count of conspiracy to commit aggravated identity theft and access device fraud.If found guilty, he could face up to five years in prison. 

Article Data
['article', 'features']
['Culture']
BBC
https://www.bbc.com/culture/article/20241017-the-terminator-how-james-camerons-science-fiction-slasher-film-predicted-our-anxieties-about-ai
None
2024-10-18T10:01:30.963Z
How 1984's The Terminator predicted our AI fears
Starring Arnold Schwarzenegger, the 1984 blockbuster The Terminator has become synonymous with the dangers of superintelligent machines. But it "helps and hinders" our understanding of AI.
In one episode of the HBO sitcom Silicon Valley, Thomas Middleditch (Richard Hendricks) is explaining his machine-learning platform Pied Piper to a focus group when one participant inevitably compares it to James Cameron's 1984 film The Terminator. "No, no, no," insists the exasperated Middleditch. "I can assure you that there is no Skynet type of situation here. No, Pied Piper will in no way become sentient and try to take over the world." Too late. He's lost the room.
With its killer robots and its rogue AI system, Skynet, The Terminator has become synonymous with the spectre of a machine intelligence that turns against its human creators. Picture editors routinely illustrate articles about AI with the chrome death's head of the film's T-800 "hunter-killer" robot. The roboticist Ronald Arkin used clips from the film in a cautionary 2013 talk called How NOT to build a Terminator.
But the film is a mixed blessing. The philosopher Nick Bostrom, whose 2014 book Superintelligence popularised the existential risk of "unaligned AI" (AI that is not aligned with human values and wellbeing) admitted that his wife "teases me about the Terminator and the robot army". In his book The Road to Conscious Machines, AI researcher Michael Woolridge frames an entire chapter with a complaint about "the Terminator narrative of AI".
There are more recent, and more plausible, influential films about AI, including Ex Machina and Her, but when it comes to the dangers of the technology, The Terminator reigns supreme 40 years after its release. "It's almost, in a funny way, more germane now than it was when it came out," Cameron told The Ringer about the film and its 1991 sequel, "because AI is now a real thing that we have to deal with, and then it was a fantasy."
This is quite an achievement for a film that is not, in fact, particularly interested in AI. First and foremost, it is a lean and lurid thriller about an unstoppable "man" chasing a scared but resourceful woman. The T-800 is an implacable killer in the vein of Michael Myers from Halloween. Cameron called it "a science-fiction slasher film". Secondarily, it is a time-travel film on the theme of "fate vs will", as Cameron put it.
The briskly sketched premise is that at some point between 1984 and 2029, the US entrusted its entire defence system to Skynet. One day, Skynet achieved superintelligence – a mind of its own – and initiated a global nuclear war. Humanity's survivors then waged a decades-long rebellion against Skynet's robot army. By 2029, the human resistance is on the verge of victory thanks to the leadership of one John Connor, so Skynet dispatches a T-800 (Arnold Schwarzenegger) to 1984 to kill John's mother-to-be Sarah (Linda Hamilton) before she becomes pregnant. The resistance responds by sending back Kyle Reese (Michael Biehn) to stop the T-800 and save Sarah. In one of those time-loop paradoxes that viewers should not examine too closely, Kyle hooks up with Sarah and turns out to be John's father. The future is saved.
The Terminator, then, is a thriller, a love story, a time-hopping rumination on free will and a satire about our dependence on technology. It is anti-corporate, anti-war, anti-gun and largely anti-machine. Technology, from answering machines to Walkmans, is involved when people get killed in this film. But it has very little to say about AI itself.
The Terminator would become one of the most profitable films of all time, grossing $78.4m, but Cameron had no expectation of creating a cultural touchstone. He wrote the screenplay in a tatty hotel in Rome in 1982 after being fired from his first directing gig, Piranha II: The Spawning, and his producer Gale Ann Hurd could only rustle up a $6.4m budget. His lead actor, a former bodybuilder of unproven talent, did not have high hopes. Schwarzenegger told a friend about "some shit movie I'm doing, take a couple of weeks".
Cameron himself expected The Terminator to get "stomped" at the box office by the autumn's two sci-fi epics: David Lynch's Dune and Peter Hyams's 2010: The Year We Make Contact, a soon-forgotten sequel to 2001: A Space Odyssey. There's an attractive synchronicity here: not only did The Terminator outperform 2010 but Skynet came to supplant 2001's murderous computer HAL 9000 as the dominant image of AI gone bad.
Long before the field of AI existed, its potential dangers manifested in the form of the robot, created by Karel Čapek in his 1921 play RUR and popularised by Fritz Lang's 1927 film Metropolis. In his excellent BFI book on The Terminator, Sean French suggests that the movie's most memorable image – the T-800 striding out of the flames, its suit of flesh melted away to expose its metallic endoskeleton – was a nod to the burning robot in Metropolis. In the 1920s, it stood to reason that machine intelligence would walk and talk, like Frankenstein's monster. The popularity of lethal robots led the science-fiction writer Isaac Asimov, in 1942, to draw up the "three laws of robotics": the first ever attempt to define ethical AI.
In the real world, the field of artificial intelligence officially began in 1956 at a summer school at Dartmouth University, organised by computer scientists John McCarthy (who coined the term) and Marvin Minsky. Their ambition was to design machines that could think like humans, but this proved much harder than they had imagined. The history of AI is one of boom and bust: a cycle of so-called "AI springs" and "AI winters". Mindboggling promises attract attention, funding and talent; their failure to materialise causes all three to slump.
The boom of the 1960s, before the scale of the technical obstacles became apparent, is known as the Golden Age of AI. Extravagant hype about "electronic brains" excited director Stanley Kubrick and writer Arthur C Clarke, who integrated AI into 1968's 2001: A Space Odyssey in the form of HAL 9000. The name (meaning Heuristically Programmed Algorithmic Computer) came from Minsky himself, hired as a consultant by Kubrick. The T-800's red eyes are surely a homage to HAL – seeing 2001 as a child set Cameron on the path to becoming a film-maker.
Daniel Crevier, a historian of AI, contrasted the HAL scenario (poorly programmed computer goes awry) with the scenario in DF Jones's 1966 thriller Colossus (computer becomes a god-like new lifeform). In Jones's novel, the US government unwisely entrusts its entire defence machinery to the titular supercomputer. Colossus achieves sentience, joins forces with its Soviet counterpart and blackmails humanity into submitting to a techno-dictatorship: surrender or face nuclear annihilation. Colossus is a proto-Skynet.
Neither HAL nor Colossus had – or needed – bodies. Cameron's brilliant innovation was to combine the out-of-control computer (Skynet) with the killer robot (the T-800). The T-800 is a single-purpose form of AI that can learn from its environment, solve problems, perform sophisticated physical tasks and deepfake voices, yet struggles to hold a conversation. Skynet, it seems, can do everything but move.
Skynet was a product of the second AI spring. While Cameron was writing the screenplay, the British-Canadian computer scientist Geoffrey Hinton was rethinking and reviving research into the neural-net approach to AI: modelling machine intelligence on the neurons in the human brain. Skynet is neural-net AI. Hinton, who has just won the Nobel Prize for physics, has recently become an AI doomer ("My intuition is: we're toast. This is the actual end of history"), but according to a New Yorker profile, he enjoyed The Terminator in 1984: "It didn't bother him that Skynet… was a neural net; he was pleased to see the technology portrayed as promising."
The name Skynet may also have been a nod to Star Wars, President Reagan's doomed dream of creating an anti-nuclear shield around the US with space-based lasers. (Fortunately for the franchise's future, it also inadvertently echoed the internet – a word that existed in 1984 but was not widely used until the 1990s.) The portmanteau names of ambitious new start-ups like IntelliCorp, Syntelligence and TeKnowledge possibly inspired Cameron to crunch down the original name of Skynet's creator, Cyber Dynamics Corporation, into Cyberdyne Systems.
Rewatching The Terminator now, it is surprising to find that the word Skynet is only uttered twice. According to Kyle Reese it was: "New. Powerful. Hooked into everything. Trusted to run it all. They say it got smart… a new order of intelligence. Then it saw all people as a threat, not just the ones on the other side. Decided our fate in a microsecond… extermination." That's the extent of the film's interest in AI. As Cameron has often said, the Terminator films are really about people rather than machines.
The blockbuster 1991 sequel Terminator 2: Judgment Day filled out the story a little. It springs from another time paradox: the central processing unit and right arm of the original Terminator survived its destruction and enabled Cyberdyne scientist Miles Bennett Dyson (Joe Morton) to design Skynet. The heroes' task now is not just to save 10-year-old John Connor from the time-travelling T-1000 but to destroy Skynet in the digital cradle. (This was Cameron's last word on the subject until he produced and co-wrote 2019's Terminator: Dark Fate. He recently told Empire magazine that all the intervening sequels were "discountable".)
In Terminator 2, a Schwarzenegger-shaped T-800 is protector rather than hunter, and therefore the bearer of exposition: "The system goes on-line August 4th, 1997. Human decisions are removed from strategic defence. Skynet begins to learn at a geometric rate. It becomes self-aware at 2:14 a.m. Eastern time, August 29th. In a panic, they try to pull the plug." Skynet fights back by launching nuclear missiles at Russia, in the knowledge that the counter-attack will devastate the US. Three billion people die in 24 hours: Judgement Day.
This is a fundamentally different account to Reese's. In the first film, Skynet overinterprets its programming by deeming all of humanity a threat. In the second, it is acting out of self-interest. The contradiction does not trouble most viewers, but it does illustrate a crucial disagreement about the existential risk of AI.
More like this:• Avatar 2 and the future of visual effects• What Alien can tell us about office life• Why Star Wars shouldn't have sequels
The layperson is likely to imagine unaligned AI as rebellious and malevolent. But the likes of Nick Bostrom insist that the real danger is from careless programming. Think of the sorcerer's broom in Disney's Fantasia: a device that obediently follows its instructions to ruinous extremes. The second type of AI is not human enough it lacks common sense and moral judgement. The first is too human - selfish, resentful, power-hungry. Both could in theory be genocidal.
The Terminator therefore both helps and hinders our understanding of AI: what it means for a machine to "think", and how it could go horrifically wrong. Many AI researchers resent the Terminator obsession altogether for exaggerating the existential risk of AI at the expense of more immediate dangers such as mass unemployment, disinformation and autonomous weapons. "First, it makes us worry about things that we probably don't need to fret about," writes Michael Woolridge. "But secondly, it draws attention away from those issues raised by AI that we should be concerned about."
Cameron revealed to Empire that he is plotting a new Terminator film which will discard all the franchise's narrative baggage but retain the core idea of "powerless" humans versus AI. If it comes off, it will be fascinating to see what the director has to say about AI now that it is something we talk - and worry - about every day. Perhaps The Terminator's most useful message to AI researchers is that of "will vs fate": human decisions determine outcomes. Nothing is inevitable.
Dorian Lynskey is the author of Everything Must Go: The Stories We Tell About the End of the World (April 2024).
--
If you liked this story, sign up for The Essential List newsletter – a handpicked selection of features, videos and can't-miss news, delivered to your inbox twice a week.
For more Culture stories from the BBC, follow us on Facebook, X and Instagram.

Article Data
['article', 'news']
['Technology']
BBC
https://www.bbc.com/news/articles/cj0467e9e43o
None
2024-10-17T05:00:49.399Z
Social media faces big changes under new Ofcom rules
Social media companies will face punishments for failing to keep children safe on their platforms, communications watchdog Ofcom has warned.Services like Facebook, Instagram and Whatsapp could face fines from the regulator if they do not comply with the new Online Safety Act - which comes into force early next year - Ofcom chief executive Dame Melanie Dawes, told the BBC.Dame Melanie said it was the responsibility of the firms - not parents or children - to make sure people were safe online.Companies will have three months from when the guidance is finalised to carry out risk assessments and make relevant changes to safeguard users.
Dame Melanie's comments come on the same day that Instagram added features to help stop sextortion.Ofcom has been putting together codes of practice since the Online Safety Act became law.The Act requires social media firms to protect children from content such as self-harm material, pornography and violent content.However, the pace of change is not quick enough for some.
Ellen Roome's 14-year-old son Jools Sweeney died in unclear circumstances after he was found unconscious in his room in April 2022. She believes he may have taken part in an online challenge that went wrong.Mrs Roome is now part of the Bereaved Parents for Online Safety group.She told the Today programme: "I don’t think anything has changed. They [the technology companies] are all waiting to see what Ofcom are going to do to enforce it, and Ofcom don’t seem to be quick enough to enforce those new powers to stop social media harming children."From us as a group of parents, we are sitting there thinking ‘when are they going to start enforcing this?’ They don’t seem to be doing enough."Platforms are supposed to remove illegal content like promoting or facilitating suicide, self-harm, and child sexual abuse. But you can still easily find content online that children shouldn’t be seeing."
Dame Melanie said that technology companies needed to be "honest and  transparent" about what their "services are actually exposing their users to"."If we don't think they've done that job well enough, we can take enforcement action, simply against that failure." 
Ofcom has already been in close contact with social networking services and Dame Melanie said when the new legal safeguards became enforceable the regulator would be "ready to go".She added: "We know that some of them are preparing but we are expecting very significant changes."Dame Melanie said changes could also include allowing people to take themselves out of group chats, without anyone else being able to see they had left.The Online Safety Act aims to force tech firms to take more responsibility for the content on their platforms.Ofcom has the power to fine companies which break the rules up to 10% of their global revenue. It can also block access to their businesses in the UK.Dr Lucie Moore is the chief executive of Cease, the Centre to End All Sexual Exploitation. She welcomed Dame Melanie’s comments about putting the onus of keeping children safe on the tech companies.However, she was disappointed by "the lack of clear definition in the plans that Ofcom has drawn up to regulate online harms", specifically on age verification methods regarding pornographic material.Additional reporting by Graham Fraser

Article Data
['article', 'news']
['Technology']
BBC
https://www.bbc.com/news/articles/ce8vedz4yk7o
None
2024-10-16T14:13:06.484Z
Firm hacked after accidentally hiring North Korean cyber criminal
A company has been hacked after accidentally hiring a North Korean cyber criminal as a remote IT worker.The unidentified firm hired the technician after he faked his employment history and personal details.Once given access to the company’s computer network, the hacker downloaded sensitive company data and sent a ransom demand.The firm which is based in the UK, US or Australia did not want to be named. It has allowed cyber responders from Secureworks to report the hack to spread awareness and warn others.It is the latest in a string of cases of western remote workers being unmasked as North Koreans.Secureworks said the IT worker, thought to be a man, was hired in the summer as a contractor.He used the firm’s remote working tools to log into the corporate network.He then secretly downloaded as much company data as possible as soon as he had gained access to internal systems.Lazarus Heist: The intercontinental ATM theft that netted $14m in two hoursNorth Korea hackers trying to steal nuclear secrets, US and UK warnHe worked for the firm for four months collecting a salary.Researchers say this was likely redirected to North Korea in a complex laundering process to evade western sanctions on the country.After the company sacked him for poor performance, it received ransom emails containing some of the stolen data and a demand to be paid a six-figure sum in cryptocurrency.If the company did not pay, the hacker said they would publish or sell the stolen information online. The firm did not disclose whether the ransom was paid.
Since 2022, authorities and cyber defenders have warned about the rise of secret North Korean workers infiltrating western companies.The US and South Korea accuse North Korea of tasking thousands of staff to take on multiple well-paid western roles remotely to earn money for the regime and avoid sanctions.In September cyber security company Mandiant said dozens of Fortune 100 companies have been found to have accidentally hired North Koreans.
But secret IT workers turning on their employers with cyber attacks is rare, according to Rafe Pilling, Director of Threat Intelligence at Secureworks."This is a serious escalation of the risk from fraudulent North Korean IT worker schemes," he said. "No longer are they just after a steady pay check, they are looking for higher sums, more quickly, through data theft and extortion, from inside the company defences."The case comes after another North Korean IT worker was caught attempting to hack their employer in July.The IT worker was hired by the cyber company KnowBe4, which quickly disabled access to their systems when it noticed strange behaviour.
"We posted the job, received resumes, conducted interviews, performed background checks, verified references, and hired the person," the firm wrote in a blog post. "We sent them their Mac workstation, and the moment it was received, it immediately started to load malware (malicious software)."Authorities are warning employers to be vigilant about new hires if they are fully remote.

